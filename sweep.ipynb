{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/config.yaml') as f:\n",
    "    default_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "#display(default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1e-06\n",
      "<class 'float'>\n",
      "1e-06\n"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict(default_config)\n",
    "print(type(args.WEIGHT_DECAY))\n",
    "print(args.WEIGHT_DECAY)\n",
    "args.WEIGHT_DECAY = float(args.WEIGHT_DECAY)\n",
    "print(type(args.WEIGHT_DECAY))\n",
    "print(args.WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이름은 직접 할당해줘야됨!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 돌릴 모델 바꾸려면 여기서 dlfma 바꿔줘야함\n",
    "args.MODEL = \"DeepCoNN\"\n",
    "print(args.DEEPCONN_VECTOR_CREATE)\n",
    "print(type(args.DEEPCONN_VECTOR_CREATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN.PY  모델 도입부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import (CNN_FM, DeepCoNN, DeepCrossNetworkModel,\n",
    "                 FactorizationMachineModel,\n",
    "                 FieldAwareFactorizationMachineModel,\n",
    "                 NeuralCollaborativeFiltering, WideAndDeepModel,\n",
    "                 seed_everything)\n",
    "from src.data import (context_data_load, context_data_loader,\n",
    "                      context_data_split, dl_data_load, dl_data_loader,\n",
    "                      dl_data_split, image_data_load, image_data_loader,\n",
    "                      image_data_split, text_data_load, text_data_loader,\n",
    "                      text_data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## DATA LOAD\n",
    "print(f'--------------- {args.MODEL} Load Data ---------------')\n",
    "if args.MODEL in ('FM', 'FFM'):\n",
    "    data = context_data_load(args)\n",
    "elif args.MODEL in ('NCF', 'WDN', 'DCN'):\n",
    "    data = dl_data_load(args)\n",
    "elif args.MODEL == 'CNN_FM':\n",
    "    data = image_data_load(args)\n",
    "elif args.MODEL == 'DeepCoNN':\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    data = text_data_load(args)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "######################## Train/Valid Split\n",
    "print(f'--------------- {args.MODEL} Train/Valid Split ---------------')\n",
    "if args.MODEL in ('FM', 'FFM'):\n",
    "    data = context_data_split(args, data)\n",
    "    data = context_data_loader(args, data)\n",
    "elif args.MODEL in ('NCF', 'WDN', 'DCN'):\n",
    "    data = dl_data_split(args, data)\n",
    "    data = dl_data_loader(args, data)\n",
    "elif args.MODEL=='CNN_FM':\n",
    "    data = image_data_split(args, data)\n",
    "    data = image_data_loader(args, data)\n",
    "elif args.MODEL=='DeepCoNN':\n",
    "    data = text_data_split(args, data)\n",
    "    data = text_data_loader(args, data)\n",
    "else:\n",
    "    pass\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sweep:\n",
    "    def __init__(self, args, data,config):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.data = data\n",
    "        self.config = config\n",
    "\n",
    "        os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"/opt/ml/input/level1_bookratingprediction_recsys-level1-recsys-05/sweep.ipynb\"\n",
    "        \n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        wandb.init(project=\"sweep_DeepCoNN\",\n",
    "            config=self.config,\n",
    "            settings=dict(start_method='thread')\n",
    "        )    \n",
    "        data = self.data\n",
    "        args = self.args\n",
    "        wandb.log({\"emb_dim\": wandb.config.emb_dim,\n",
    "        \"latent_dim\":wandb.config.latent_dim})\n",
    "        print(f'--------------- INIT {args.MODEL} ---------------')\n",
    "        if args.MODEL=='FM':\n",
    "            print(\"wandb.config.emb_dim = \", wandb.config.emb_dim)\n",
    "            print(type(wandb.config.emb_dim))\n",
    "            args.FM_EMBED_DIM = wandb.config.emb_dim\n",
    "            model = FactorizationMachineModel(args, data)\n",
    "        elif args.MODEL=='FFM':\n",
    "            args.FFM_EMBED_DIM = wandb.config.emb_dim\n",
    "            model = FieldAwareFactorizationMachineModel(args, data)\n",
    "        elif args.MODEL=='NCF':\n",
    "            tmp = (wandb.config.mlp_dim,wandb.config.mlp_dim)\n",
    "            print(\"wandb.config.emb_dim = \", wandb.config.emb_dim)\n",
    "            print(\"wandb.config.mlp_dim = \", tmp)\n",
    "            print(\"wandb.config.drop_out = \", wandb.config.drop_out)\n",
    "            args.NCF_EMBED_DIM = wandb.config.emb_dim\n",
    "            args.NCF_MLP_DIMS = tmp\n",
    "            args.NCF_DROPOUT = wandb.config.drop_out\n",
    "            model = NeuralCollaborativeFiltering(args, data)\n",
    "        elif args.MODEL=='WDN':\n",
    "            args.WDN_EMBED_DIM = wandb.config.emb_dim\n",
    "            model = WideAndDeepModel(args, data)\n",
    "        elif args.MODEL=='DCN':\n",
    "            args.DCN_EMBED_DIM = wandb.config.emb_dim\n",
    "            model = DeepCrossNetworkModel(args, data)\n",
    "        elif args.MODEL=='CNN_FM':\n",
    "            args.CNN_FM_EMBED_DIM = wandb.config.emb_dim\n",
    "            model = CNN_FM(args, data)\n",
    "        elif args.MODEL=='DeepCoNN':\n",
    "            print(\"wandb.config.emb_dim = \", wandb.config.emb_dim)\n",
    "            print(\"wandb.config.latent_dim = \", wandb.config.latent_dim)\n",
    "            args.DEEPCONN_EMBED_DIM = wandb.config.emb_dim\n",
    "            args.DEEPCONN_LATENT_DIM = wandb.config.latent_dim\n",
    "            model = DeepCoNN(args, data)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #wandb.config.update(args)\n",
    "        # wandb.watch(model)\n",
    "        ######################## TRAIN\n",
    "        print(f'--------------- {args.MODEL} TRAINING ---------------')\n",
    "        rmse = model.train()\n",
    "        ######################## INFERENCE\n",
    "        print(f'--------------- {args.MODEL} PREDICT ---------------')\n",
    "        if args.MODEL in ('FM', 'FFM', 'NCF', 'WDN', 'DCN'):\n",
    "            predicts = model.predict(data['test_dataloader'])\n",
    "        elif args.MODEL=='CNN_FM':\n",
    "            predicts  = model.predict(data['test_dataloader'])\n",
    "        elif args.MODEL=='DeepCoNN':\n",
    "            predicts  = model.predict(data['test_dataloader'])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ######################## PREDICT GET IN RANGE\n",
    "        def adjust_predict(y):\n",
    "            if y < 1.0:\n",
    "                return 1.0\n",
    "            elif y > 10.0:\n",
    "                return 10.0\n",
    "            return y\n",
    "        \n",
    "        predicts = list(map(adjust_predict, predicts))\n",
    "\n",
    "        ######################## SAVE PREDICT\n",
    "        print(f'--------------- SAVE {args.MODEL} PREDICT ---------------')\n",
    "        submission = pd.read_csv(args.DATA_PATH + 'sample_submission.csv')\n",
    "        if args.MODEL in ('FM', 'FFM', 'NCF', 'WDN', 'DCN', 'CNN_FM', 'DeepCoNN'):\n",
    "            submission['rating'] = predicts\n",
    "        else:\n",
    "            pass\n",
    "        train1 = pd.read_csv('./data/train_ratings.csv')\n",
    "\n",
    "        count=train1.groupby(\"user_id\").size()\n",
    "        dfcount = pd.DataFrame(count, columns=[\"count\"])\n",
    "        submission=pd.merge(submission,dfcount, how='left', on='user_id')\n",
    "        submission['count'] = submission['count'].fillna(0)\n",
    "        submission.set_index(\"user_id\",inplace = True)\n",
    "\n",
    "        for row in submission.itertuples():\n",
    "            if row[3] == 0 :\n",
    "                submission.at[row[0],\"rating\"] = 7\n",
    "\n",
    "        submission = submission.reset_index()\n",
    "        submission = submission.drop(['count'], axis=1)\n",
    "\n",
    "\n",
    "        now = time.localtime()\n",
    "        now_date = time.strftime('%Y%m%d', now)\n",
    "        now_hour = time.strftime('%X', now)\n",
    "        save_time = now_date + '_' + now_hour.replace(':', '')\n",
    "        submission.to_csv('submit/{}_{}_{}.csv'.format(save_time, args.MODEL, round(rmse, 5), index=False))\n",
    "\n",
    "        wandb.finish()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기 아래에 있는 sweep_configuration 에 있는 Parameters 값에 있는 것들만 랜덤 생성됨.\n",
    "\n",
    "지금은 FM, FFM에 있는 embeding dim을 실험하기 위한 코드\n",
    "나머지 모델들 돌릴경우에는 아래에 추가해주면 됨.\n",
    "\n",
    "처음에 \n",
    "################# 돌릴 모델 바꾸려면 여기서\n",
    "args.MODEL = \"FM\"\n",
    "\n",
    "코드에서 돌릴 모델 이름 써줘야 됨~!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'minimize', 'name': 'rmse'}, \n",
    "    'parameters':{\n",
    "        'emb_dim':{'values': [16,12,8,4,2]},\n",
    "        'mlp_dim':{'values': [16,12,8,4,2]},\n",
    "        'drop_out':{'values': [0.2,0.05]}\n",
    "        }}\n",
    "config={\n",
    "        \"epochs\": args.EPOCHS,\n",
    "        \"batch_size\": args.BATCH_SIZE,\n",
    "        \"lr\": args.LR,\n",
    "        \"emb_dim\": 16,\n",
    "        'mlp_dim': (16,16),\n",
    "        'drop_out': 0.2\n",
    "        }\n",
    "\"\"\"\n",
    "######이거는 NCF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########DeepCoNN\n",
    "config={\n",
    "        \"epochs\": args.EPOCHS,\n",
    "        \"batch_size\": args.BATCH_SIZE,\n",
    "        \"lr\": args.LR,\n",
    "        \"emb_dim\": 32,\n",
    "        \"latent_dim\":10,\n",
    "        \"conv1doutdim\":50,\n",
    "        \"kernel_size\":3,\n",
    "        \"word_dim\":768,\n",
    "        \"out_dim\":32\n",
    "        }\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'minimize', 'name': 'val_loss'}, \n",
    "    'parameters':{\n",
    "        \"emb_dim\": {'max':64, 'min':2},\n",
    "        \"latent_dim\":{'max':20, 'min':2}\n",
    "        }}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args.EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env \"WANDB_NOTEBOOK_NAME\" \"/opt/ml/input/level1_bookratingprediction_recsys-level1-recsys-05/sweep.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"/opt/ml/input/level1_bookratingprediction_recsys-level1-recsys-05/sweep.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sibal = sweep(args, data,config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wandb.agent(sweep_id, function=sibal.train,count =3)\n",
    "\n",
    "count = \"\"\n",
    "여기에 몇번 돌릴지 넣으면 돌아감!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep=sweep_configuration,project='sweep_DeepCoNN')\n",
    "wandb.agent(sweep_id, function=sibal.train,count =100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
