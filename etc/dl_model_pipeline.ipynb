{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69b93c44-013e-4a69-b0a5-ffff71425c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import tqdm\n",
    "import pdb\n",
    "from scipy.sparse import csr_matrix, linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e78675fd-d561-425a-ab09-542475c61699",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"../data/books.csv\")\n",
    "train = pd.read_csv(\"../data/train_ratings.csv\")\n",
    "test = pd.read_csv(\"../data/test_ratings.csv\")\n",
    "users = pd.read_csv(\"../data/users.csv\")\n",
    "sub = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9329e444-12ad-4556-9110-5369012ac2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_data_load\n",
    "ids = pd.concat([train['user_id'], sub['user_id']]).unique()\n",
    "isbns = pd.concat([train['isbn'], sub['isbn']]).unique()\n",
    "\n",
    "idx2user = {idx:id for idx, id in enumerate(ids)}\n",
    "idx2isbn = {idx:isbn for idx, isbn in enumerate(isbns)}\n",
    "\n",
    "user2idx = {id:idx for idx, id in idx2user.items()}\n",
    "isbn2idx = {isbn:idx for idx, isbn in idx2isbn.items()}\n",
    "\n",
    "train['user_id'] = train['user_id'].map(user2idx)\n",
    "sub['user_id'] = sub['user_id'].map(user2idx)\n",
    "test['user_id'] = test['user_id'].map(user2idx)\n",
    "\n",
    "train['isbn'] = train['isbn'].map(isbn2idx)\n",
    "sub['isbn'] = sub['isbn'].map(isbn2idx)\n",
    "test['isbn'] = test['isbn'].map(isbn2idx)\n",
    "\n",
    "field_dims = np.array([len(user2idx), len(isbn2idx)], dtype=np.uint32)\n",
    "\n",
    "data = {\n",
    "        'train':train,\n",
    "        'test':test.drop(['rating'], axis=1),\n",
    "        'field_dims':field_dims,\n",
    "        'users':users,\n",
    "        'books':books,\n",
    "        'sub':sub,\n",
    "        'idx2user':idx2user,\n",
    "        'idx2isbn':idx2isbn,\n",
    "        'user2idx':user2idx,\n",
    "        'isbn2idx':isbn2idx,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27c4459f-a018-468e-9534-613b698a3bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306790</th>\n",
       "      <td>6313</td>\n",
       "      <td>129772</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306791</th>\n",
       "      <td>1879</td>\n",
       "      <td>129773</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306792</th>\n",
       "      <td>1879</td>\n",
       "      <td>129774</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306793</th>\n",
       "      <td>1879</td>\n",
       "      <td>129775</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306794</th>\n",
       "      <td>1879</td>\n",
       "      <td>129776</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306795 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id    isbn  rating\n",
       "0             0       0       4\n",
       "1             1       0       7\n",
       "2             2       0       8\n",
       "3             3       0       8\n",
       "4             4       0       9\n",
       "...         ...     ...     ...\n",
       "306790     6313  129772       7\n",
       "306791     1879  129773       6\n",
       "306792     1879  129774       7\n",
       "306793     1879  129775       7\n",
       "306794     1879  129776      10\n",
       "\n",
       "[306795 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a689268b-144b-4f8f-b27b-f17c618edb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68069, 149570], dtype=uint32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['field_dims'] #user개수 item개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffede7b-83e6-4d64-8246-78540b799046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl_data_split()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                                                        data['train'].drop(['rating'], axis=1),\n",
    "                                                        data['train']['rating'],\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42,\n",
    "                                                        shuffle=True\n",
    "                                                        )\n",
    "data['X_train'], data['X_valid'], data['y_train'], data['y_valid'] = X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e71dd14-5c39-47f8-ae00-8256e01e18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl_data_loader()\n",
    "BATCH_SIZE = 1024\n",
    "DATA_SHUFFLE = True\n",
    "train_dataset = TensorDataset(torch.LongTensor(data['X_train'].values), torch.LongTensor(data['y_train'].values))\n",
    "valid_dataset = TensorDataset(torch.LongTensor(data['X_valid'].values), torch.LongTensor(data['y_valid'].values))\n",
    "test_dataset = TensorDataset(torch.LongTensor(data['test'].values))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=DATA_SHUFFLE)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=DATA_SHUFFLE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "data['train_dataloader'], data['valid_dataloader'], data['test_dataloader'] = train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a2192-1ee6-46e7-ae91-1b9d57226033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, field_dims: np.ndarray, embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b8563a-b01c-41de-83a3-bdb09d0cc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\n",
    "        super().__init__()\n",
    "        layers = list()\n",
    "        for embed_dim in embed_dims:\n",
    "            layers.append(torch.nn.Linear(input_dim, embed_dim))\n",
    "            layers.append(torch.nn.BatchNorm1d(embed_dim))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            layers.append(torch.nn.Dropout(p=dropout))\n",
    "            input_dim = embed_dim\n",
    "        if output_layer:\n",
    "            layers.append(torch.nn.Linear(input_dim, 1))\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, embed_dim)``\n",
    "        \"\"\"\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f5431e-7e8e-44d9-be36-04876535cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _NeuralCollaborativeFiltering(nn.Module):\n",
    "\n",
    "    def __init__(self, field_dims, user_field_idx, item_field_idx, embed_dim, mlp_dims, dropout):\n",
    "        super().__init__()\n",
    "        self.user_field_idx = user_field_idx\n",
    "        self.item_field_idx = item_field_idx\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout, output_layer=False)\n",
    "        self.fc = torch.nn.Linear(mlp_dims[-1] + embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_user_fields)``\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        user_x = x[:, self.user_field_idx].squeeze(1)\n",
    "        item_x = x[:, self.item_field_idx].squeeze(1)\n",
    "        gmf = user_x * item_x\n",
    "        x = self.mlp(x.view(-1, self.embed_output_dim))\n",
    "        x = torch.cat([gmf, x], dim=1)\n",
    "        x = self.fc(x).squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dadecf63-528b-4d97-bc2d-8a8782327f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCollaborativeFiltering:\n",
    "\n",
    "    def __init__(self, args, data):\n",
    "        super().__init__()\n",
    "\n",
    "        self.criterion = RMSELoss()\n",
    "\n",
    "        self.train_dataloader = data['train_dataloader']\n",
    "        self.valid_dataloader = data['valid_dataloader']\n",
    "        self.field_dims = data['field_dims']\n",
    "        self.user_field_idx = np.array((0, ), dtype=np.long)\n",
    "        self.item_field_idx=np.array((1, ), dtype=np.long)\n",
    "\n",
    "        self.embed_dim = args.NCF_EMBED_DIM\n",
    "        self.epochs = args.EPOCHS\n",
    "        self.learning_rate = args.LR\n",
    "        self.weight_decay = args.WEIGHT_DECAY\n",
    "        self.log_interval = 100\n",
    "\n",
    "        self.device = args.DEVICE\n",
    "\n",
    "        self.mlp_dims = args.NCF_MLP_DIMS\n",
    "        self.dropout = args.NCF_DROPOUT\n",
    "\n",
    "        self.model = _NeuralCollaborativeFiltering(self.field_dims, user_field_idx=self.user_field_idx, item_field_idx=self.item_field_idx,\n",
    "                                                    embed_dim=self.embed_dim, mlp_dims=self.mlp_dims, dropout=self.dropout).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.learning_rate, amsgrad=True, weight_decay=self.weight_decay)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "      # model: type, optimizer: torch.optim, train_dataloader: DataLoader, criterion: torch.nn, device: str, log_interval: int=100\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            tk0 = tqdm.tqdm(self.train_dataloader, smoothing=0, mininterval=1.0)\n",
    "            for i, (fields, target) in enumerate(tk0):\n",
    "                fields, target = fields.to(self.device), target.to(self.device)\n",
    "                y = self.model(fields)\n",
    "                loss = self.criterion(y, target.float())\n",
    "                self.model.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                if (i + 1) % self.log_interval == 0:\n",
    "                    tk0.set_postfix(loss=total_loss / self.log_interval)\n",
    "                    total_loss = 0\n",
    "            wandb.log({\"loss\":total_loss},step =epoch)\n",
    "            rmse_score = self.predict_train()\n",
    "            wandb.log({\"rmse\":rmse_score},step = epoch)\n",
    "            print('epoch:', epoch, 'validation: rmse:', rmse_score)\n",
    "\n",
    "\n",
    "    def predict_train(self):\n",
    "        self.model.eval()\n",
    "        targets, predicts = list(), list()\n",
    "        with torch.no_grad():\n",
    "            for fields, target in tqdm.tqdm(self.valid_dataloader, smoothing=0, mininterval=1.0):\n",
    "                fields, target = fields.to(self.device), target.to(self.device)\n",
    "                y = self.model(fields)\n",
    "                targets.extend(target.tolist())\n",
    "                predicts.extend(y.tolist())\n",
    "        return rmse(targets, predicts)\n",
    "\n",
    "\n",
    "    def predict(self, dataloader):\n",
    "        self.model.eval()\n",
    "        predicts = list()\n",
    "        with torch.no_grad():\n",
    "            for fields in tqdm.tqdm(dataloader, smoothing=0, mininterval=1.0):\n",
    "                fields = fields[0].to(self.device)\n",
    "                y = self.model(fields)\n",
    "                predicts.extend(y.tolist())\n",
    "        return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afc5a9-df98-414b-948c-1a029503e627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
