{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "\n",
    "users = pd.read_csv(DATA_PATH + 'users.csv')\n",
    "books = pd.read_csv(DATA_PATH + 'books.csv')\n",
    "train = pd.read_csv(DATA_PATH + 'train_ratings.csv')\n",
    "test = pd.read_csv(DATA_PATH + 'test_ratings.csv')\n",
    "sub = pd.read_csv(DATA_PATH + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149570 entries, 0 to 149569\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   isbn                 149570 non-null  object \n",
      " 1   book_title           149570 non-null  object \n",
      " 2   book_author          149570 non-null  object \n",
      " 3   year_of_publication  149570 non-null  float64\n",
      " 4   publisher            149570 non-null  object \n",
      " 5   img_url              149570 non-null  object \n",
      " 6   language             82343 non-null   object \n",
      " 7   category             80719 non-null   object \n",
      " 8   summary              82343 non-null   object \n",
      " 9   img_path             149570 non-null  object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['location_city'] = users['location'].apply(lambda x: x.split(',')[0])\n",
    "users['location_state'] = users['location'].apply(lambda x: x.split(',')[1])\n",
    "users['location_country'] = users['location'].apply(lambda x: x.split(',')[2])\n",
    "users = users.drop(['location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users['location_country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " usa               43991\n",
       " canada             6208\n",
       " germany            3526\n",
       " united kingdom     2914\n",
       "                    2101\n",
       " australia          1791\n",
       " spain              1653\n",
       " france              794\n",
       " italy               770\n",
       " switzerland         451\n",
       " new zealand         448\n",
       " netherlands         403\n",
       " portugal            325\n",
       " austria             251\n",
       " malaysia            167\n",
       " singapore           129\n",
       " sweden              120\n",
       " ireland             107\n",
       " belgium             104\n",
       " brazil              103\n",
       " finland              89\n",
       " philippines          80\n",
       " argentina            77\n",
       " japan                74\n",
       " mexico               65\n",
       " denmark              61\n",
       " norway               54\n",
       " israel               48\n",
       " india                39\n",
       " romania              39\n",
       "Name: location_country, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['location_country'].value_counts()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['location_city'] = users['location_city'].str.strip()\n",
    "users['location_state'] = users['location_state'].str.strip()\n",
    "users['location_country'] = users['location_country'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['location_city'] = users['location_city'].str.replace(r'[^a-zA-Z]', '', regex=True)\n",
    "users['location_state'] = users['location_state'].str.replace(r'[^a-zA-Z]', '', regex=True)\n",
    "users['location_country'] = users['location_country'].str.replace(r'[^a-zA-Z]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "location_country\n",
    "'''\n",
    "# null & na & universe & etc\n",
    "null_repl = [\n",
    "    'universe', 'na', '', 'lava', 'petrolwarnation', 'space', 'lachineternelle',\n",
    "    'faraway', 'everywhereandanywhere', 'hereandthere', 'tdzimi', 'naontheroad',\n",
    "    'unknown'\n",
    "]\n",
    "for keyword in null_repl:\n",
    "    users.loc[users['location_country'] == keyword, 'location_country'] = 'null'\n",
    "users.loc[users['location_country'] == 'c', 'location_country'] = 'null'\n",
    "# australia\n",
    "australia_repl = [\n",
    "    'newsouthwales', 'queensland', 'tasmania', 'victoria', 'nsw', 'southaustralia'\n",
    "]\n",
    "for keyword in australia_repl:\n",
    "    users.loc[users['location_country'].str.contains(keyword), 'location_country'] = 'australia'\n",
    "# italy\n",
    "users.loc[users['location_country'].str.contains('ital'), 'location_country'] = 'italy'\n",
    "users.loc[users['location_country'].str.contains('ferrara'), 'location_country'] = 'italy'\n",
    "users.loc[users['location_country'].str.contains('veneziagiulia'), 'location_country'] = 'italy'\n",
    "users.loc[users['location_country'].str.contains('ineurope'), 'location_country'] = 'italy'\n",
    "# germany\n",
    "users.loc[users['location_country'].str.contains('deut'), 'location_country'] = 'germany'\n",
    "users.loc[users['location_country'].str.contains('germ'), 'location_country'] = 'germany'\n",
    "users.loc[users['location_country'].str.contains('berlin'), 'location_country'] = 'germany'\n",
    "users.loc[users['location_country'].str.contains('niedersachsen'), 'location_country'] = 'germany'\n",
    "# united kingdom\n",
    "uk_repls = [\n",
    "    'unitedkingdom', 'eng', 'king', 'wales', 'scotland', 'aberdeenshire', 'camden', 'unitedkindgonm',\n",
    "    'middlesex', 'nottinghamshire', 'westyorkshire', 'cambridgeshire', 'sthelena', 'northyorkshire',\n",
    "    'obviously'\n",
    "]\n",
    "for keyword in uk_repls:\n",
    "    users.loc[users['location_country'].str.contains(keyword), 'location_country'] = 'united kingdom'\n",
    "users.loc[users['location_country'] == 'uk', 'location_country'] = 'united kingdom'\n",
    "# ireland\n",
    "users.loc[users['location_country'].str.contains('countycork'), 'location_country'] = 'ireland'\n",
    "users.loc[users['location_country'].str.contains('cocarlow'), 'location_country'] = 'ireland'\n",
    "# france\n",
    "users.loc[users['location_country'].str.contains('fran'), 'location_country'] = 'france'\n",
    "users.loc[users['location_country'].str.contains('paris'), 'location_country'] = 'france'\n",
    "# spain\n",
    "spain_repl = [\n",
    "    'esp', 'catal', 'galiza', 'euskalherria', 'lleida', 'gipuzkoa', 'orense', 'pontevedra', 'almera',\n",
    "    'bergued', 'andalucia'\n",
    "]\n",
    "for keyword in spain_repl:\n",
    "    users.loc[users['location_country'].str.contains(keyword), 'location_country'] = 'spain'\n",
    "# portugal\n",
    "users.loc[users['location_country'].str.contains('oeiras'), 'location_country'] = 'portugal'\n",
    "# belgium\n",
    "users.loc[users['location_country'].str.contains('labelgique'), 'location_country'] = 'belgium'\n",
    "# austria\n",
    "users.loc[users['location_country'].str.contains('eu'), 'location_country'] = 'austria'\n",
    "# swiss\n",
    "users.loc[users['location_country'].str.contains('lasuisse'), 'location_country'] = 'switzerland'\n",
    "# finland\n",
    "users.loc[users['location_country'].str.contains('etelsuomi'), 'location_country'] = 'finland'\n",
    "# usa\n",
    "usa_repl = [\n",
    "    'unitedstaes', 'america', 'usa', 'state', 'sate', 'cali', 'dc', 'oregon', 'texas', 'florida',\n",
    "    'newhampshire', 'newmexico', 'newjersey', 'newyork', 'virginia', 'bermuda', 'illinois', 'michigan',\n",
    "    'arizona', 'indiana', 'minnesota', 'tennessee', 'dakota', 'connecticut', 'wisconsin', 'ohio',\n",
    "    'maryland', 'northcarolina', 'massachusetts', 'colorado', 'washington', 'maine', 'georgia', 'oklahoma',\n",
    "    'maracopa', 'districtofcolumbia', 'saintloius', 'orangeco', 'aroostook', 'arkansas', 'montana',\n",
    "    'rhodeisland', 'nevada', 'kern', 'fortbend', 'nebraska', 'usofa', 'alabama', 'csa', 'polk',\n",
    "    'alachua', 'austin', 'alaska', 'hawaii', 'worcester', 'iowa', 'cherokee', 'shelby', 'stthomasi',\n",
    "    'vanwert', 'kansas', 'idaho', 'tn', 'framingham', 'pender', 'ysa', 'arizona', 'morgan', 'rutherford'\n",
    "]\n",
    "for keyword in usa_repl:\n",
    "    users.loc[users['location_country'].str.contains(keyword), 'location_country'] = 'usa'\n",
    "users.loc[users['location_country'] == 'us', 'location_country'] = 'usa'\n",
    "users.loc[users['location_country'] == 'ca', 'location_country'] = 'usa'\n",
    "users.loc[users['location_country'] == 'il', 'location_country'] = 'usa'\n",
    "users.loc[users['location_country'] == 'ua', 'location_country'] = 'usa'\n",
    "# cananda\n",
    "canada_repl = [\n",
    "    'cananda', 'british', 'newfoundland', 'newbrunswick', 'alberta', 'ontario', 'lkjlj', 'bc',\n",
    "    'novascotia', 'kcb', 'quebec', 'maricopa', 'travelling', 'vvh', 'saskatchewan'\n",
    "]\n",
    "for keyword in canada_repl:\n",
    "    users.loc[users['location_country'].str.contains(keyword), 'location_country'] = 'canada'\n",
    "# new zealand\n",
    "users.loc[users['location_country'] == 'nz', 'location_country'] = 'newzealand'\n",
    "users.loc[users['location_country'].str.contains('otago'), 'location_country'] = 'newzealand'\n",
    "users.loc[users['location_country'].str.contains('auckland'), 'location_country'] = 'newzealand'\n",
    "# malaysia\n",
    "users.loc[users['location_country'].str.contains('kedah'), 'location_country'] = 'malaysia'\n",
    "# uae\n",
    "users.loc[users['location_country'].str.contains('uae'), 'location_country'] = 'unitedarabemirates'\n",
    "# kuwait\n",
    "users.loc[users['location_country'].str.contains('quit'), 'location_country'] = 'kuwait'\n",
    "# phillipines\n",
    "users.loc[users['location_country'].str.contains('phill'), 'location_country'] = 'philippines'\n",
    "users.loc[users['location_country'].str.contains('metromanila'), 'location_country'] = 'philippines'\n",
    "# uruguay\n",
    "users.loc[users['location_country'].str.contains('urugua'), 'location_country'] = 'uruguay'\n",
    "# panama\n",
    "users.loc[users['location_country'].str.contains('republicofpanama'), 'location_country'] = 'panama'\n",
    "# trinidadandtobago\n",
    "users.loc[users['location_country'].str.contains('westindies'), 'location_country'] = 'trinidadandtobago'\n",
    "# guernsey\n",
    "users.loc[users['location_country'].str.contains('alderney'), 'location_country'] = 'guernsey'\n",
    "# japan\n",
    "users.loc[users['location_country'].str.contains('okinawa'), 'location_country'] = 'japan'\n",
    "# korea\n",
    "users.loc[users['location_country'].str.contains('seoul'), 'location_country'] = 'southkorea'\n",
    "# brazil\n",
    "users.loc[users['location_country'].str.contains('disritofederal'), 'location_country'] = 'brazil'\n",
    "\n",
    "\n",
    "'''\n",
    "location_state\n",
    "'''\n",
    "# usa\n",
    "usa_state_repl = [\n",
    "    'usa', 'texas', 'tx', 'california', 'massachusetts', 'michigan', 'carolina', 'florida', 'colorado', 'pennsylvania',\n",
    "    'newyork', 'newjersey', 'virginia', 'dc', 'washington', 'iowa', 'illinois', 'georgia', 'kansas', 'missouri',\n",
    "    'mississippi', 'oregon', 'arizona', 'ohio', 'tennessee', 'idaho', 'alaska', 'alabama', 'minnesota', 'utah',\n",
    "    'kentucky', 'rhodeisland', 'maryland', 'louisiana', 'indiana', 'connecticut', 'wisconsin', 'newhampshire',\n",
    "    'nevada', 'oklahoma', 'georgia', 'maine', 'newmexico', 'nebraska', 'wyoming', 'frenchquarter', 'fl', 'nebr', 'ct',\n",
    "\n",
    "]\n",
    "for keyword in usa_state_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains(keyword)), 'location_country'] = 'usa'\n",
    "# canada\n",
    "canada_state_repl = [\n",
    "    'britishcolumbia', 'newbrunswick', 'novascotia', 'ontario', 'alberta', 'quebec', 'saskatchewan',\n",
    "    'manitoba', \n",
    "]\n",
    "for keyword in canada_state_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains(keyword)), 'location_country'] = 'canada'\n",
    "# mexico\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('jalisco')), 'location_country'] = 'mexico'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('michoacan')), 'location_country'] = 'mexico'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('morelos')), 'location_country'] = 'mexico'\n",
    "# united kingdom\n",
    "uk_state_repl = [\n",
    "    'newhampshire', 'nottinghamshire', 'england', 'middlesex', 'midlothian', 'scotland', 'westyorkshire',\n",
    "    'canterbury', 'wiltshire', 'kent', 'london', 'cambs', 'herts', 'isleofman', 'surrey', 'cheshire',\n",
    "    'gloucestershire', 'aberdeenshire'\n",
    "]\n",
    "for keyword in uk_state_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains(keyword)), 'location_country'] = 'united kingdom'\n",
    "# ireland\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('dublin')), 'location_country'] = 'ireland'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('wicklow')), 'location_country'] = 'ireland'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('colimerick')), 'location_country'] = 'ireland'\n",
    "# australia\n",
    "australia_state_repl = [\n",
    "    'newsouthwales', 'victoria', 'australiancapitalterritory', 'southaustralia', 'nsw'\n",
    "]\n",
    "for keyword in australia_state_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains(keyword)), 'location_country'] = 'australia'\n",
    "# germany\n",
    "germany_state_repl = [\n",
    "    'nordrheinwestfalen', 'bayern', 'hamburg', 'badenwuerttemberg', 'badenwrttemberg', 'sachsen', 'berlin',\n",
    "    'stuttgart', 'nrw', 'bavaria', 'bremen'\n",
    "]\n",
    "for keyword in germany_state_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains(keyword)), 'location_country'] = 'germany'\n",
    "# switzerland\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('bern')), 'location_country'] = 'switzerland'\n",
    "# austria\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('niederoesterreich')), 'location_country'] = 'austria'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('vienna')), 'location_country'] = 'austria'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('wien')), 'location_country'] = 'austria'\n",
    "# slovenia\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('ljubljanskaregija')), 'location_country'] = 'slovenia'\n",
    "# spain\n",
    "spain_state_repl = [\n",
    "    'catalunya', 'pontevedra', 'madrid', 'bizkaia', 'asturias', 'pontevedra', 'barcelona', 'pasvasco',\n",
    "    'espaa', 'badajoz', 'gipuzkoa', 'valencia', 'galicia'\n",
    "]\n",
    "for keyword in spain_state_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains(keyword)), 'location_country'] = 'spain'\n",
    "# portugal\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('lisboa')), 'location_country'] = 'portugal'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('coimbra')), 'location_country'] = 'portugal'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('porto')), 'location_country'] = 'portugal'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('estremadura')), 'location_country'] = 'portugal'\n",
    "# netherlands\n",
    "netherlands_state_repl = [\n",
    "    'noordholland', 'utrecht', 'zuidholland', 'overijssel', 'friesland', 'northholland', 'schleswigholstein',\n",
    "    'zh', 'twente', \n",
    "]\n",
    "for keyword in netherlands_state_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains(keyword)), 'location_country'] = 'netherlands'\n",
    "# belgium\n",
    "belgium_state_repl = [\n",
    "    'vlaamsbrabant', 'liege'\n",
    "]\n",
    "for keyword in belgium_state_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains(keyword)), 'location_country'] = 'belgium'\n",
    "# new zealand\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('auckland')), 'location_country'] = 'newzealand'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('northisland')), 'location_country'] = 'newzealand'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('waikato')), 'location_country'] = 'newzealand'\n",
    "# italy\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('italia')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('toscana')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('piemonte')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('lombardia')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('gorizia')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'] == 're'), 'location_country'] = 'italy'\n",
    "# greece\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('townofbali')), 'location_country'] = 'greece'\n",
    "# nigeria\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('imostate')), 'location_country'] = 'nigeria'\n",
    "# southafrica\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('westerncape')), 'location_country'] = 'southafrica'\n",
    "# romania\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('ilfov')), 'location_country'] = 'romania'\n",
    "# malaysia\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('penang')), 'location_country'] = 'malaysia'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('negerisembilan')), 'location_country'] = 'malaysia'\n",
    "# indonesia\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('jakarta')), 'location_country'] = 'indonesia'\n",
    "# philippines\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('laguna')), 'location_country'] = 'philippines'\n",
    "# singapore\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('singapore')), 'location_country'] = 'singapore'\n",
    "# pakistan\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('punjab')), 'location_country'] = 'pakistan'\n",
    "# denmark\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('jutland')), 'location_country'] = 'denmark'\n",
    "# france\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('lorraine')), 'location_country'] = 'france'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('hautegaronne')), 'location_country'] = 'france'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('heraut')), 'location_country'] = 'france'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('rhnealpes')), 'location_country'] = 'france'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('iledefrance')), 'location_country'] = 'france'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('paca')), 'location_country'] = 'france'\n",
    "# uruguay\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('montevideo')), 'location_country'] = 'uruguay'\n",
    "# argentina\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('buenosaires')), 'location_country'] = 'argentina'\n",
    "# peru\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('southamerica')), 'location_country'] = 'peru'\n",
    "# chile\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('santiago')), 'location_country'] = 'chile'\n",
    "# japan\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('iwakuni')), 'location_country'] = 'japan'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_state'].str.contains('tokyo')), 'location_country'] = 'japan'\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "location_city\n",
    "'''\n",
    "# usa\n",
    "usa_city_repl = [\n",
    "    'losang', 'seattle', 'sanf', 'sand', 'newyork', 'newark', 'newbedford', 'portland', 'cincinnati',\n",
    "    'houston', 'albuquerque', 'chicago', 'austin', 'beaverton', 'raleigh', 'richmond', 'fairbanks',\n",
    "    'minneapolis', 'stlouis', 'tucson', 'oakland', 'boston', 'kansascity', 'denver', 'springfield',\n",
    "    'topeka', 'dallas', 'asheville', 'buffalo', 'fremont', 'stpaul', 'elcajon', 'miami', 'marysville',\n",
    "    'baltimore', 'charleston', 'santamonica', 'knoxville', 'rochester', 'orlando', 'coloradosprings',\n",
    "    'arlington', 'pensacola', 'sanjose', 'cedarrapids', 'olympia', 'lasvegas', 'mercerisland',\n",
    "    'encinitas', 'omaha', 'lawrence', 'sacramento', 'norfolk', 'kirkwood', 'tallahassee', 'lexington',\n",
    "    'kalamazoo', 'orleans', 'desmoines', 'aurora', 'annarbor', 'newbern', 'somerville', 'lakeland',\n",
    "    'hartford', 'tigard', 'phoenix', 'irvine', 'sanantonio', 'mesa', 'brooklyn', 'philadelphia',\n",
    "    'lacey', 'greenbay', 'pittsburg', 'wichita', 'elizabeth', 'murrieta', 'batonrouge', 'yuma',\n",
    "    'baycity', 'lynchburg', 'santabarbara', 'statenisland', 'saintpaul', 'lakewood', 'fallschurch',\n",
    "    'northhaven', 'frederick', 'milwaukie', 'cary', 'stcharles', 'lewiston', 'virginiabeach',\n",
    "    'longbranch', 'indianapolis', 'portales', 'fountainvalley', 'sebastopol', 'washington', 'louisville',\n",
    "    'millersburg'\n",
    "]\n",
    "for keyword in usa_city_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains(keyword)), 'location_country'] = 'usa'\n",
    "# canada\n",
    "canada_city_repl = [\n",
    "    'calgary', 'vancouver', 'toronto', 'ottawa', 'fredericton', 'victoria', 'hamilton', 'montreal',\n",
    "    'kelowna', 'winnipeg', 'saskatoon', 'halifax', 'edmonton', 'kitchener', 'regina', 'lethbridge',\n",
    "\n",
    "]\n",
    "for keyword in canada_city_repl:\n",
    "    users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains(keyword)), 'location_country'] = 'canada'\n",
    "# italy\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('milano')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('roma')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('rome')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('genova')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('torino')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('perugia')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('salerno')), 'location_country'] = 'italy'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('firenze')), 'location_country'] = 'italy'\n",
    "# united kingdom\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('london')), 'location_country'] = 'united kingdom'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('manchester')), 'location_country'] = 'united kingdom'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('cambridge')), 'location_country'] = 'united kingdom'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('york')), 'location_country'] = 'united kingdom'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('birmingham')), 'location_country'] = 'united kingdom'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('edinburgh')), 'location_country'] = 'united kingdom'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('newcastle')), 'location_country'] = 'united kingdom'\n",
    "# germany\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('hamburg')), 'location_country'] = 'germany'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('berlin')), 'location_country'] = 'germany'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('augsburg')), 'location_country'] = 'germany'\n",
    "# france\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('paris')), 'location_country'] = 'france'\n",
    "# spain\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('barcelona')), 'location_country'] = 'spain'\n",
    "# finland\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('helsinki')), 'location_country'] = 'finland'\n",
    "# australia\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('melbourne')), 'location_country'] = 'australia'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('sidney')), 'location_country'] = 'australia'\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('canberra')), 'location_country'] = 'australia'\n",
    "# singapore\n",
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('singapore')), 'location_country'] = 'singapore'\n",
    "\n",
    "'''\n",
    "모든 null 값을 다 볼 순 없으므로,\n",
    "user_id 별 데이터 많은 순서대로 null 값 처리\n",
    "'''\n",
    "# usa\n",
    "usa_uids = [\n",
    "    83671, 179718, 187065, 104278, 146230, 93565, 67663, 84795, 175100,\n",
    "    273190, 51350, 19493, 226745, 57620, 125031, 113663, 178201, 91631,\n",
    "    83443, 239535, 135228, 23680, 259264, 209229, 929, 168036, 50129,\n",
    "    129368, 136465, 8937, 84523, 241749, 48743, 132188, 270897, 171045,\n",
    "    44842, 115473, 1131, 91017, 68768, 167587, 135411, 30889, 221557,\n",
    "    39195, 154346, 273110, 29497, 223816, 38718, 175529, 186238, 239449,\n",
    "    141543, 77676, 258277, 240113, 172486, 34988, 112818, 129474, 46295,\n",
    "    142041, 268035, 176102, 126985, 93386, 114601, 30650, 24105, 170850,\n",
    "    28372, 207651, 122802, 129389, 266764, 269140, 50504, 52993, 170208,\n",
    "    162264, 45641, 226556, 241214\n",
    "\n",
    "]\n",
    "for uid in usa_uids:\n",
    "    users.loc[users['user_id'] == uid, 'location_country'] = 'usa'    \n",
    "# uk\n",
    "users.loc[users['user_id'] == 178522, 'location_country'] = 'united kingdom'\n",
    "users.loc[users['user_id'] == 5476, 'location_country'] = 'united kingdom'\n",
    "users.loc[users['user_id'] == 237064, 'location_country'] = 'united kingdom'\n",
    "users.loc[users['user_id'] == 241537, 'location_country'] = 'united kingdom'\n",
    "# ireland\n",
    "users.loc[users['user_id'] == 26432, 'location_country'] = 'ireland'\n",
    "# canada\n",
    "canada_uids = [44089, 79188, 176100, 34087, 172962, 103160, 206693]\n",
    "for uid in canada_uids:\n",
    "    users.loc[users['user_id'] == uid, 'location_country'] = 'canada'\n",
    "# france\n",
    "users.loc[users['user_id'] == 179641, 'location_country'] = 'france'\n",
    "# germany\n",
    "users.loc[users['user_id'] == 276538, 'location_country'] = 'germany'\n",
    "users.loc[users['user_id'] == 102169, 'location_country'] = 'germany'\n",
    "# austria\n",
    "users.loc[users['user_id'] == 3923, 'location_country'] = 'austria'\n",
    "users.loc[users['user_id'] == 14393, 'location_country'] = 'austria'\n",
    "# portugal\n",
    "users.loc[users['user_id'] == 164581, 'location_country'] = 'portugal'\n",
    "# australia\n",
    "users.loc[users['user_id'] == 11399, 'location_country'] = 'australia'\n",
    "# malaysia\n",
    "users.loc[users['user_id'] == 30445, 'location_country'] = 'malaysia'\n",
    "users.loc[users['user_id'] == 28543, 'location_country'] = 'malaysia'\n",
    "# philippines\n",
    "users.loc[users['user_id'] == 131023, 'location_country'] = 'philippines'\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.drop(['location_city', 'location_state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.loc[users['location_country'] == 'null', 'location_country'] = 'empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id 별 책 권 수 count 열 추가\n",
    "count = train.groupby(\"user_id\").size()\n",
    "dfcount = pd.DataFrame(count, columns=[\"count\"])\n",
    "\n",
    "users = users.merge(dfcount, on='user_id', how='left')\n",
    "users = users.loc[users['count'].notna()]\n",
    "users['count'] = users['count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('../data/loc_users.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en       78823\n",
       "de        1282\n",
       "es        1017\n",
       "fr         883\n",
       "it         123\n",
       "nl          67\n",
       "pt          47\n",
       "da          37\n",
       "ca          23\n",
       "ms          10\n",
       "no           6\n",
       "zh-CN        3\n",
       "ja           3\n",
       "gl           3\n",
       "ru           3\n",
       "la           3\n",
       "el           1\n",
       "th           1\n",
       "ro           1\n",
       "fa           1\n",
       "eo           1\n",
       "gd           1\n",
       "ga           1\n",
       "vi           1\n",
       "zh-TW        1\n",
       "ko           1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149570 entries, 0 to 149569\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   isbn                 149570 non-null  object \n",
      " 1   book_title           149570 non-null  object \n",
      " 2   book_author          149570 non-null  object \n",
      " 3   year_of_publication  149570 non-null  float64\n",
      " 4   publisher            149570 non-null  object \n",
      " 5   img_url              149570 non-null  object \n",
      " 6   language             82343 non-null   object \n",
      " 7   category             80719 non-null   object \n",
      " 8   summary              82343 non-null   object \n",
      " 9   img_path             149570 non-null  object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn    book_title           book_author  year_of_publication  \\\n",
       "0  0002005018  Clara Callan  Richard Bruce Wright               2001.0   \n",
       "\n",
       "               publisher                                            img_url  \\\n",
       "0  HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "  language       category                                            summary  \\\n",
       "0       en  ['Actresses']  In a small town in Canada, Clara Callan reluct...   \n",
       "\n",
       "                            img_path  \n",
       "0  images/0002005018.01.THUMBZZZ.jpg  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>usa</th>\n",
       "      <td>20158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canada</th>\n",
       "      <td>3114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>germany</th>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united kingdom</th>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>australia</th>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trinidadandtobago</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palau</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guinea</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jersey</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macedonia</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   location_country\n",
       "usa                           20158\n",
       "canada                         3114\n",
       "germany                        1097\n",
       "united kingdom                  859\n",
       "australia                       469\n",
       "...                             ...\n",
       "trinidadandtobago                 1\n",
       "palau                             1\n",
       "guinea                            1\n",
       "jersey                            1\n",
       "macedonia                         1\n",
       "\n",
       "[110 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(users.loc[users['age'].isna(), 'location_country'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usa               45128\n",
       "canada             6446\n",
       "germany            3574\n",
       "united kingdom     3043\n",
       "australia          1819\n",
       "                  ...  \n",
       "zambia                1\n",
       "kosovo                1\n",
       "tonga                 1\n",
       "honduras              1\n",
       "elsalvador            1\n",
       "Name: location_country, Length: 142, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.loc[:, 'location_country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>231251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woodstock</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7361</th>\n",
       "      <td>231252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woodstock</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51468</th>\n",
       "      <td>22510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woodstock</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52516</th>\n",
       "      <td>147646</td>\n",
       "      <td>23.0</td>\n",
       "      <td>woodstock</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   age location_city location_state location_country\n",
       "4100    231251   NaN     woodstock                            null\n",
       "7361    231252   NaN     woodstock                            null\n",
       "51468    22510   NaN     woodstock                            null\n",
       "52516   147646  23.0     woodstock                            null"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.loc[(users['location_country'] == 'null') & (users['location_city'].str.contains('woodstock'))]#['location_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>36656</td>\n",
       "      <td>28.0</td>\n",
       "      <td>manila</td>\n",
       "      <td>na</td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>66428</td>\n",
       "      <td>16.0</td>\n",
       "      <td>dasmarias</td>\n",
       "      <td>cavite</td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>76301</td>\n",
       "      <td>19.0</td>\n",
       "      <td>pasigcity</td>\n",
       "      <td></td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>86809</td>\n",
       "      <td>26.0</td>\n",
       "      <td>manila</td>\n",
       "      <td>metromanila</td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>88142</td>\n",
       "      <td>19.0</td>\n",
       "      <td>santiagocity</td>\n",
       "      <td>na</td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63539</th>\n",
       "      <td>169023</td>\n",
       "      <td>13.0</td>\n",
       "      <td>sanjuan</td>\n",
       "      <td>metromanila</td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64539</th>\n",
       "      <td>127510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>quezoncity</td>\n",
       "      <td>metromanila</td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64648</th>\n",
       "      <td>211563</td>\n",
       "      <td>31.0</td>\n",
       "      <td>manila</td>\n",
       "      <td>na</td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65689</th>\n",
       "      <td>162937</td>\n",
       "      <td>19.0</td>\n",
       "      <td>valenciacity</td>\n",
       "      <td></td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66832</th>\n",
       "      <td>205468</td>\n",
       "      <td>29.0</td>\n",
       "      <td>quezoncity</td>\n",
       "      <td>metromanila</td>\n",
       "      <td>philippines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   age location_city location_state location_country\n",
       "919      36656  28.0        manila             na      philippines\n",
       "1131     66428  16.0     dasmarias         cavite      philippines\n",
       "1211     76301  19.0     pasigcity                     philippines\n",
       "1280     86809  26.0        manila    metromanila      philippines\n",
       "1291     88142  19.0  santiagocity             na      philippines\n",
       "...        ...   ...           ...            ...              ...\n",
       "63539   169023  13.0       sanjuan    metromanila      philippines\n",
       "64539   127510   NaN    quezoncity    metromanila      philippines\n",
       "64648   211563  31.0        manila             na      philippines\n",
       "65689   162937  19.0  valenciacity                     philippines\n",
       "66832   205468  29.0    quezoncity    metromanila      philippines\n",
       "\n",
       "[85 rows x 5 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#users.loc[users['location_country'].str.contains('phil')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users['location_country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        isbn  rating\n",
       "0        8  0002005018       4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.merge(users, on='user_id', how='left').merge(books, on='isbn', how='left')\n",
    "test_df = test.merge(users, on='user_id', how='left').merge(books, on='isbn', how='left')\n",
    "train_df = train_df.drop(['location_city', 'location_state'], axis=1)\n",
    "test_df = test_df.drop(['location_city', 'location_state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 306795 entries, 0 to 306794\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   user_id              306795 non-null  int64  \n",
      " 1   isbn                 306795 non-null  object \n",
      " 2   rating               306795 non-null  int64  \n",
      " 3   age                  214133 non-null  float64\n",
      " 4   location_country     306795 non-null  object \n",
      " 5   book_title           306795 non-null  object \n",
      " 6   book_author          306795 non-null  object \n",
      " 7   year_of_publication  306795 non-null  float64\n",
      " 8   publisher            306795 non-null  object \n",
      " 9   img_url              306795 non-null  object \n",
      " 10  language             187711 non-null  object \n",
      " 11  category             185574 non-null  object \n",
      " 12  summary              187711 non-null  object \n",
      " 13  img_path             306795 non-null  object \n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 35.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usa               215445\n",
       "canada             29129\n",
       "united kingdom     12197\n",
       "germany             9834\n",
       "null                7031\n",
       "                   ...  \n",
       "zambia                 1\n",
       "mozambique             1\n",
       "niger                  1\n",
       "algeria                1\n",
       "paraguay               1\n",
       "Name: location_country, Length: 138, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['location_country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116744/870193709.py:1: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  train_df.loc[train_df['location_country'] == 'null', 'user_id'].value_counts()[120:140]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28543     6\n",
       "206693    6\n",
       "45641     6\n",
       "226556    6\n",
       "178458    6\n",
       "241214    6\n",
       "200009    6\n",
       "233117    6\n",
       "233928    6\n",
       "265925    6\n",
       "117390    6\n",
       "11708     6\n",
       "228913    6\n",
       "129531    6\n",
       "219729    6\n",
       "26782     6\n",
       "163194    5\n",
       "105124    5\n",
       "237797    5\n",
       "38775     5\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['location_country'] == 'null', 'user_id'].value_counts()[120:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>233117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>didsbury</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  age location_city location_state location_country\n",
       "4482   233117  NaN      didsbury                            null"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.loc[users['user_id'] == 233117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_country</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63137</th>\n",
       "      <td>200009</td>\n",
       "      <td>0380701340</td>\n",
       "      <td>8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>montevista</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "      <td>Creed for the Third Millennium</td>\n",
       "      <td>Colleen McCullough</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>Avon</td>\n",
       "      <td>http://images.amazon.com/images/P/0380701340.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>In a future America ravaged by wars and enduri...</td>\n",
       "      <td>images/0380701340.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82430</th>\n",
       "      <td>200009</td>\n",
       "      <td>0452281431</td>\n",
       "      <td>8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>montevista</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "      <td>Beauty's Punishment (Sleeping Beauty)</td>\n",
       "      <td>A.N. Roquelaure</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>Plume Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0452281431.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0452281431.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96059</th>\n",
       "      <td>200009</td>\n",
       "      <td>034536676X</td>\n",
       "      <td>8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>montevista</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "      <td>The World According to Garp</td>\n",
       "      <td>John Irving</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034536676X.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>T. S. Garp, a man with high ambitions for an a...</td>\n",
       "      <td>images/034536676X.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203370</th>\n",
       "      <td>200009</td>\n",
       "      <td>0061020613</td>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>montevista</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "      <td>Witches Abroad</td>\n",
       "      <td>Terry Pratchett</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>http://images.amazon.com/images/P/0061020613.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>But the road to Genua is bumpy, and along the ...</td>\n",
       "      <td>images/0061020613.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206957</th>\n",
       "      <td>200009</td>\n",
       "      <td>0061054909</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>montevista</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "      <td>Love in Vein</td>\n",
       "      <td>Poppy Z. Brite</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Eos</td>\n",
       "      <td>http://images.amazon.com/images/P/0061054909.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>A sexy new repackaging of the extremely popula...</td>\n",
       "      <td>images/0061054909.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251291</th>\n",
       "      <td>200009</td>\n",
       "      <td>0688172849</td>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>montevista</td>\n",
       "      <td></td>\n",
       "      <td>null</td>\n",
       "      <td>Test Pattern</td>\n",
       "      <td>Marjorie Klein</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>William Morrow &amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0688172849.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0688172849.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        isbn  rating   age location_city location_state  \\\n",
       "63137    200009  0380701340       8  30.0    montevista                  \n",
       "82430    200009  0452281431       8  30.0    montevista                  \n",
       "96059    200009  034536676X       8  30.0    montevista                  \n",
       "203370   200009  0061020613       9  30.0    montevista                  \n",
       "206957   200009  0061054909       2  30.0    montevista                  \n",
       "251291   200009  0688172849       9  30.0    montevista                  \n",
       "\n",
       "       location_country                             book_title  \\\n",
       "63137              null         Creed for the Third Millennium   \n",
       "82430              null  Beauty's Punishment (Sleeping Beauty)   \n",
       "96059              null            The World According to Garp   \n",
       "203370             null                         Witches Abroad   \n",
       "206957             null                           Love in Vein   \n",
       "251291             null                           Test Pattern   \n",
       "\n",
       "               book_author  year_of_publication                 publisher  \\\n",
       "63137   Colleen McCullough               1986.0                      Avon   \n",
       "82430      A.N. Roquelaure               1984.0               Plume Books   \n",
       "96059          John Irving               1994.0          Ballantine Books   \n",
       "203370     Terry Pratchett               2002.0               HarperTorch   \n",
       "206957      Poppy Z. Brite               1995.0                       Eos   \n",
       "251291      Marjorie Klein               2000.0  William Morrow & Company   \n",
       "\n",
       "                                                  img_url language  \\\n",
       "63137   http://images.amazon.com/images/P/0380701340.0...       en   \n",
       "82430   http://images.amazon.com/images/P/0452281431.0...      NaN   \n",
       "96059   http://images.amazon.com/images/P/034536676X.0...       en   \n",
       "203370  http://images.amazon.com/images/P/0061020613.0...       en   \n",
       "206957  http://images.amazon.com/images/P/0061054909.0...       en   \n",
       "251291  http://images.amazon.com/images/P/0688172849.0...      NaN   \n",
       "\n",
       "           category                                            summary  \\\n",
       "63137   ['Fiction']  In a future America ravaged by wars and enduri...   \n",
       "82430           NaN                                                NaN   \n",
       "96059   ['Fiction']  T. S. Garp, a man with high ambitions for an a...   \n",
       "203370  ['Fiction']  But the road to Genua is bumpy, and along the ...   \n",
       "206957  ['Fiction']  A sexy new repackaging of the extremely popula...   \n",
       "251291          NaN                                                NaN   \n",
       "\n",
       "                                 img_path  \n",
       "63137   images/0380701340.01.THUMBZZZ.jpg  \n",
       "82430   images/0452281431.01.THUMBZZZ.jpg  \n",
       "96059   images/034536676X.01.THUMBZZZ.jpg  \n",
       "203370  images/0061020613.01.THUMBZZZ.jpg  \n",
       "206957  images/0061054909.01.THUMBZZZ.jpg  \n",
       "251291  images/0688172849.01.THUMBZZZ.jpg  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['user_id'] == 200009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fr    849\n",
       "en    498\n",
       "de      6\n",
       "es      6\n",
       "nl      3\n",
       "no      1\n",
       "da      1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['location_country'] == 'france', 'language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: location_state, dtype: object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['location_country'] == 'canada']['location_state']#.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " california          28888\n",
       " ontario             12979\n",
       " texas               12253\n",
       " new york            10557\n",
       " georgia             10537\n",
       " n/a                  9050\n",
       " florida              8868\n",
       " illinois             8393\n",
       " washington           8077\n",
       " pennsylvania         8032\n",
       " england              7370\n",
       " missouri             7326\n",
       "                      6919\n",
       " ohio                 6761\n",
       " virginia             6716\n",
       " oregon               6207\n",
       " new jersey           5969\n",
       " michigan             5764\n",
       " british columbia     5360\n",
       " north carolina       5100\n",
       "Name: location_state, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['location_state'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['1940-1949']</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "      <td>images/0060973129.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Medical']</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "      <td>images/0374157065.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>A Chinese immigrant who is convinced she is dy...</td>\n",
       "      <td>images/0399135782.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0425176428</td>\n",
       "      <td>What If?: The World's Foremost Military Histor...</td>\n",
       "      <td>Robert Cowley</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['History']</td>\n",
       "      <td>Essays by respected military historians, inclu...</td>\n",
       "      <td>images/0425176428.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149565</th>\n",
       "      <td>067161746X</td>\n",
       "      <td>The Bachelor Home Companion: A Practical Guide...</td>\n",
       "      <td>P.J. O'Rourke</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Pocket Books</td>\n",
       "      <td>http://images.amazon.com/images/P/067161746X.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Humor']</td>\n",
       "      <td>A tongue-in-cheek survival guide for single pe...</td>\n",
       "      <td>images/067161746X.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149566</th>\n",
       "      <td>0767907566</td>\n",
       "      <td>All Elevations Unknown: An Adventure in the He...</td>\n",
       "      <td>Sam Lightner</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Broadway Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0767907566.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Nature']</td>\n",
       "      <td>A daring twist on the travel-adventure genre t...</td>\n",
       "      <td>images/0767907566.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149567</th>\n",
       "      <td>0884159221</td>\n",
       "      <td>Why stop?: A guide to Texas historical roadsid...</td>\n",
       "      <td>Claude Dooley</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Lone Star Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0884159221.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0884159221.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149568</th>\n",
       "      <td>0912333022</td>\n",
       "      <td>The Are You Being Served? Stories: 'Camping In...</td>\n",
       "      <td>Jeremy Lloyd</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Kqed Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0912333022.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>These hilarious stories by the creator of publ...</td>\n",
       "      <td>images/0912333022.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149569</th>\n",
       "      <td>1569661057</td>\n",
       "      <td>Dallas Street Map Guide and Directory, 2000 Ed...</td>\n",
       "      <td>Mapsco</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>American Map Corporation</td>\n",
       "      <td>http://images.amazon.com/images/P/1569661057.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/1569661057.01.THUMBZZZ.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149570 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              isbn                                         book_title  \\\n",
       "0       0002005018                                       Clara Callan   \n",
       "1       0060973129                               Decision in Normandy   \n",
       "2       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "3       0399135782                             The Kitchen God's Wife   \n",
       "4       0425176428  What If?: The World's Foremost Military Histor...   \n",
       "...            ...                                                ...   \n",
       "149565  067161746X  The Bachelor Home Companion: A Practical Guide...   \n",
       "149566  0767907566  All Elevations Unknown: An Adventure in the He...   \n",
       "149567  0884159221  Why stop?: A guide to Texas historical roadsid...   \n",
       "149568  0912333022  The Are You Being Served? Stories: 'Camping In...   \n",
       "149569  1569661057  Dallas Street Map Guide and Directory, 2000 Ed...   \n",
       "\n",
       "                 book_author  year_of_publication                 publisher  \\\n",
       "0       Richard Bruce Wright               2001.0     HarperFlamingo Canada   \n",
       "1               Carlo D'Este               1991.0           HarperPerennial   \n",
       "2           Gina Bari Kolata               1999.0      Farrar Straus Giroux   \n",
       "3                    Amy Tan               1991.0          Putnam Pub Group   \n",
       "4              Robert Cowley               2000.0  Berkley Publishing Group   \n",
       "...                      ...                  ...                       ...   \n",
       "149565         P.J. O'Rourke               1987.0              Pocket Books   \n",
       "149566          Sam Lightner               2001.0            Broadway Books   \n",
       "149567         Claude Dooley               1985.0           Lone Star Books   \n",
       "149568          Jeremy Lloyd               1997.0                Kqed Books   \n",
       "149569                Mapsco               1999.0  American Map Corporation   \n",
       "\n",
       "                                                  img_url language  \\\n",
       "0       http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "1       http://images.amazon.com/images/P/0060973129.0...       en   \n",
       "2       http://images.amazon.com/images/P/0374157065.0...       en   \n",
       "3       http://images.amazon.com/images/P/0399135782.0...       en   \n",
       "4       http://images.amazon.com/images/P/0425176428.0...       en   \n",
       "...                                                   ...      ...   \n",
       "149565  http://images.amazon.com/images/P/067161746X.0...       en   \n",
       "149566  http://images.amazon.com/images/P/0767907566.0...       en   \n",
       "149567  http://images.amazon.com/images/P/0884159221.0...      NaN   \n",
       "149568  http://images.amazon.com/images/P/0912333022.0...       en   \n",
       "149569  http://images.amazon.com/images/P/1569661057.0...      NaN   \n",
       "\n",
       "             category                                            summary  \\\n",
       "0       ['Actresses']  In a small town in Canada, Clara Callan reluct...   \n",
       "1       ['1940-1949']  Here, for the first time in paperback, is an o...   \n",
       "2         ['Medical']  Describes the great flu epidemic of 1918, an o...   \n",
       "3         ['Fiction']  A Chinese immigrant who is convinced she is dy...   \n",
       "4         ['History']  Essays by respected military historians, inclu...   \n",
       "...               ...                                                ...   \n",
       "149565      ['Humor']  A tongue-in-cheek survival guide for single pe...   \n",
       "149566     ['Nature']  A daring twist on the travel-adventure genre t...   \n",
       "149567            NaN                                                NaN   \n",
       "149568    ['Fiction']  These hilarious stories by the creator of publ...   \n",
       "149569            NaN                                                NaN   \n",
       "\n",
       "                                 img_path  \n",
       "0       images/0002005018.01.THUMBZZZ.jpg  \n",
       "1       images/0060973129.01.THUMBZZZ.jpg  \n",
       "2       images/0374157065.01.THUMBZZZ.jpg  \n",
       "3       images/0399135782.01.THUMBZZZ.jpg  \n",
       "4       images/0425176428.01.THUMBZZZ.jpg  \n",
       "...                                   ...  \n",
       "149565  images/067161746X.01.THUMBZZZ.jpg  \n",
       "149566  images/0767907566.01.THUMBZZZ.jpg  \n",
       "149567  images/0884159221.01.THUMBZZZ.jpg  \n",
       "149568  images/0912333022.01.THUMBZZZ.jpg  \n",
       "149569  images/1569661057.01.THUMBZZZ.jpg  \n",
       "\n",
       "[149570 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,5,figsize=(20,8))\n",
    "for country, ax_ in zip(f['location_country'], ax.flatten()):\n",
    "    users[(users['location_country']==country)]['age'].value_counts().sort_index().plot(ax=ax_, title=country)\n",
    "plt.xlim(0,100)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
